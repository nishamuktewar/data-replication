{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dataset, get_handler\n",
    "from model import get_net\n",
    "from training import Training\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3f9a889490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123\n",
    "num_images = 10\n",
    "dataset_name = 'CALTECH'\n",
    "    \n",
    "args_pool = {\n",
    "    'CALTECH':\n",
    "    {\n",
    "        'n_epoch': 10,\n",
    "        'n_classes': 10,\n",
    "        'fc_only': True,\n",
    "        'transform':\n",
    "        {\n",
    "            'train': transforms.Compose([transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "                                         transforms.RandomRotation(degrees=15),\n",
    "                                         transforms.ColorJitter(),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])]),\n",
    "            'test': transforms.Compose([transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "        },\n",
    "        'loader_tr_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_te_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_sample_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'optimizer_args': {'lr': 0.001}\n",
    "    }\n",
    "}\n",
    "   \n",
    "args = args_pool[dataset_name]\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datapool/256_ObjectCategoriesSubset/train\n",
      "== Found 822 items \n",
      "== Found 10 classes\n",
      "['/026.cake', '/057.dolphin-101', '/064.elephant-101', '/086.golden-gate-bridge', '/087.goldfish', '/170.rainbow', '/212.teapot', '/213.teddy-bear', '/239.washing-machine', '/241.waterfall']\n",
      "['/datapool/256_ObjectCategoriesSubset/train/026.cake/026_0003.jpg'\n",
      " '/datapool/256_ObjectCategoriesSubset/train/026.cake/026_0004.jpg'\n",
      " '/datapool/256_ObjectCategoriesSubset/train/026.cake/026_0006.jpg'\n",
      " '/datapool/256_ObjectCategoriesSubset/train/026.cake/026_0008.jpg']\n",
      "/datapool/256_ObjectCategoriesSubset/valid\n",
      "== Found 212 items \n",
      "== Found 10 classes\n",
      "['/026.cake', '/057.dolphin-101', '/064.elephant-101', '/086.golden-gate-bridge', '/087.goldfish', '/170.rainbow', '/212.teapot', '/213.teddy-bear', '/239.washing-machine', '/241.waterfall']\n",
      "['/datapool/256_ObjectCategoriesSubset/valid/213.teddy-bear/213_0005.jpg'\n",
      " '/datapool/256_ObjectCategoriesSubset/valid/213.teddy-bear/213_0007.jpg'\n",
      " '/datapool/256_ObjectCategoriesSubset/valid/213.teddy-bear/213_0012.jpg'\n",
      " '/datapool/256_ObjectCategoriesSubset/valid/213.teddy-bear/213_0014.jpg']\n",
      "class_indices:  [(0, '/026.cake'), (1, '/057.dolphin-101'), (2, '/064.elephant-101'), (3, '/086.golden-gate-bridge'), (4, '/087.goldfish'), (5, '/170.rainbow'), (6, '/212.teapot'), (7, '/213.teddy-bear'), (8, '/239.washing-machine'), (9, '/241.waterfall')]\n",
      "x_train:  822\n",
      "y_train:  torch.Size([822])\n",
      "x_test:  212\n",
      "y_test:  torch.Size([212])\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x_train, y_train, x_test, y_test = get_dataset(dataset_name)\n",
    "print(\"x_train: \", len(x_train))\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_test: \", len(x_test))\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_net(dataset_name)\n",
    "handler = get_handler(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extraction\n",
      "epoch\ttrain_loss\ttest_loss\ttrain_acc\ttest_acc\n",
      "1\t2.3141\t\t2.1218\t\t0.237226\t\t0.254717\n",
      "2\t2.0545\t\t1.9216\t\t0.36618\t\t0.382075\n"
     ]
    }
   ],
   "source": [
    "training = Training(x_train, y_train, x_test, y_test, net, handler, args)\n",
    "training.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.check_accuracy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replicating training set 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_replicated = np.concatenate([x_train, x_train, x_train, x_train, x_train, x_train, x_train, x_train, x_train, x_train])\n",
    "y_train_replicated = torch.cat([y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train])\n",
    "print(\"x_train_replicated: \", len(x_train_replicated))\n",
    "print(\"y_train_replicated: \", y_train_replicated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_replicated = get_net(dataset_name)\n",
    "handler_replicated = get_handler(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the performance is way better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_training = Training(x_train_replicated, y_train_replicated, x_test, y_test, net_replicated, handler_replicated, args)\n",
    "rep_training.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_training.check_accuracy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how about using original data but 10*10 epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pool = {\n",
    "    'CALTECH':\n",
    "    {\n",
    "        'n_epoch': 10*10,\n",
    "        'n_classes': 10,\n",
    "        'fc_only': True,\n",
    "        'transform':\n",
    "        {\n",
    "            'train': transforms.Compose([transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "                                         transforms.RandomRotation(degrees=15),\n",
    "                                         transforms.ColorJitter(),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])]),\n",
    "            'test': transforms.Compose([transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "        },\n",
    "        'loader_tr_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_te_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_sample_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'optimizer_args': {'lr': 0.001}\n",
    "    }\n",
    "}\n",
    "   \n",
    "args = args_pool[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_100epochs = get_net(dataset_name)\n",
    "handler_100epochs = get_handler(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_100epochs = Training(x_train, y_train, x_test, y_test, net_100epochs, handler_100epochs, args)\n",
    "training_100epochs.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_100epochs.check_accuracy(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_dl]",
   "language": "python",
   "name": "conda-env-env_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
