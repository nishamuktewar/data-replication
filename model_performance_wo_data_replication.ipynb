{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dataset, get_handler\n",
    "from model import get_net\n",
    "from training import Training\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a14124470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123\n",
    "num_images = 10\n",
    "dataset_name = 'CALTECH'\n",
    "    \n",
    "args_pool = {\n",
    "    'CALTECH':\n",
    "    {\n",
    "        'n_epoch': 10,\n",
    "        'n_classes': 10,\n",
    "        'fc_only': True,\n",
    "        'transform':\n",
    "        {\n",
    "            'train': transforms.Compose([transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])]),\n",
    "            'test': transforms.Compose([transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "        },\n",
    "        'loader_tr_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_te_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_sample_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'optimizer_args': {'lr': 0.001}\n",
    "    }\n",
    "}\n",
    "   \n",
    "args = args_pool[dataset_name]\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/026.cake', '/057.dolphin-101', '/064.elephant-101', '/086.golden-gate-bridge', '/087.goldfish', '/170.rainbow', '/212.teapot', '/213.teddy-bear', '/239.washing-machine', '/241.waterfall']\n",
      "['/home/nisha/data/256_ObjectCategoriesSubset/train/170.rainbow/170_0003.jpg'\n",
      " '/home/nisha/data/256_ObjectCategoriesSubset/train/170.rainbow/170_0005.jpg'\n",
      " '/home/nisha/data/256_ObjectCategoriesSubset/train/170.rainbow/170_0007.jpg'\n",
      " '/home/nisha/data/256_ObjectCategoriesSubset/train/170.rainbow/170_0012.jpg']\n",
      "['/026.cake', '/057.dolphin-101', '/064.elephant-101', '/086.golden-gate-bridge', '/087.goldfish', '/170.rainbow', '/212.teapot', '/213.teddy-bear', '/239.washing-machine', '/241.waterfall']\n",
      "['/home/nisha/data/256_ObjectCategoriesSubset/valid/241.waterfall/241_0015.jpg'\n",
      " '/home/nisha/data/256_ObjectCategoriesSubset/valid/241.waterfall/241_0020.jpg'\n",
      " '/home/nisha/data/256_ObjectCategoriesSubset/valid/241.waterfall/241_0023.jpg'\n",
      " '/home/nisha/data/256_ObjectCategoriesSubset/valid/241.waterfall/241_0028.jpg']\n",
      "class_indices:  [(0, '/026.cake'), (1, '/057.dolphin-101'), (2, '/064.elephant-101'), (3, '/086.golden-gate-bridge'), (4, '/087.goldfish'), (5, '/170.rainbow'), (6, '/212.teapot'), (7, '/213.teddy-bear'), (8, '/239.washing-machine'), (9, '/241.waterfall')]\n",
      "x_train:  654\n",
      "y_train:  torch.Size([654])\n",
      "x_test:  168\n",
      "y_test:  torch.Size([168])\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x_train, y_train, x_test, y_test = get_dataset(dataset_name)\n",
    "print(\"x_train: \", len(x_train))\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_test: \", len(x_test))\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_net(dataset_name)\n",
    "handler = get_handler(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extraction\n",
      "epoch\ttrain_loss\ttest_loss\ttrain_acc\ttest_acc\n",
      "1\t2.3224\t\t2.1863\t\t0.224771\t\t0.238095\n",
      "2\t2.1032\t\t1.9929\t\t0.334862\t\t0.309524\n",
      "3\t1.9386\t\t1.8545\t\t0.434251\t\t0.446429\n",
      "4\t1.795\t\t1.704\t\t0.555046\t\t0.535714\n",
      "5\t1.6807\t\t1.5911\t\t0.617737\t\t0.589286\n",
      "6\t1.5571\t\t1.4856\t\t0.685015\t\t0.660714\n",
      "7\t1.4336\t\t1.3761\t\t0.752294\t\t0.708333\n",
      "8\t1.3627\t\t1.2896\t\t0.799694\t\t0.767857\n",
      "9\t1.2709\t\t1.2043\t\t0.827217\t\t0.77381\n",
      "10\t1.176\t\t1.1567\t\t0.847095\t\t0.767857\n"
     ]
    }
   ],
   "source": [
    "training = Training(x_train, y_train, x_test, y_test, net, handler, args)\n",
    "training.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678571428571429"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.check_accuracy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replicating training set 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_replicated:  6540\n",
      "y_train_replicated:  torch.Size([6540])\n"
     ]
    }
   ],
   "source": [
    "x_train_replicated = np.concatenate([x_train, x_train, x_train, x_train, x_train, x_train, x_train, x_train, x_train, x_train])\n",
    "y_train_replicated = torch.cat([y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train])\n",
    "print(\"x_train_replicated: \", len(x_train_replicated))\n",
    "print(\"y_train_replicated: \", y_train_replicated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_replicated = get_net(dataset_name)\n",
    "handler_replicated = get_handler(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the performance is way better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extraction\n",
      "epoch\ttrain_loss\ttest_loss\ttrain_acc\ttest_acc\n",
      "1\t1.6335\t\t1.1347\t\t0.853211\t\t0.821429\n",
      "2\t0.9167\t\t0.73\t\t0.940367\t\t0.892857\n",
      "3\t0.6355\t\t0.558\t\t0.954128\t\t0.928571\n"
     ]
    }
   ],
   "source": [
    "rep_training = Training(x_train_replicated, y_train_replicated, x_test, y_test, net_replicated, handler_replicated, args)\n",
    "rep_training.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_training.check_accuracy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how about using original data but 10*10 epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pool = {\n",
    "    'CALTECH':\n",
    "    {\n",
    "        'n_epoch': 10*10,\n",
    "        'n_classes': 10,\n",
    "        'fc_only': True,\n",
    "        'transform':\n",
    "        {\n",
    "            'train': transforms.Compose([transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])]),\n",
    "            'test': transforms.Compose([transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "        },\n",
    "        'loader_tr_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_te_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'loader_sample_args': {'batch_size': 25, 'num_workers': 1},\n",
    "        'optimizer_args': {'lr': 0.001}\n",
    "    }\n",
    "}\n",
    "   \n",
    "args = args_pool[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_100epochs = get_net(dataset_name)\n",
    "handler_100epochs = get_handler(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_100epochs = Training(x_train, y_train, x_test, y_test, net_100epochs, handler_100epochs, args)\n",
    "training_100epochs.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_100epochs.check_accuracy(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_dl]",
   "language": "python",
   "name": "conda-env-env_dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
